{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "ac576a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from core.pose_utils import Keypoints2Image, pad_keypoints\n",
    "\n",
    "import cv2\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "from core.segment import Segmentor\n",
    "from copy import deepcopy\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3c247b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT = WIDTH = 256 # target resolution\n",
    "kp2img = Keypoints2Image('openpose_body_25')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "id": "2f41bd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_dir = '../data/img_highres/'\n",
    "dst_dir = '../data/img_256/'\n",
    "mask_dir = '../data/mask_256/'\n",
    "multi_dst_dir = '../data/img_multi_256/'\n",
    "multi_mask_dir = '../data/mask_multi_256/'\n",
    "\n",
    "os.makedirs(multi_dst_dir, exist_ok=True)\n",
    "os.makedirs(multi_mask_dir, exist_ok=True)\n",
    "\n",
    "df = pd.read_pickle(\"../data/deepfashion_1.pickle\")\n",
    "df.drop(index=df[df.keypoints.isnull()].index, inplace=True)\n",
    "#df.to_pickle(\"../data/deepfashion_1.pickle\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "id": "3a6c8290",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_empty_sample():\n",
    "    image = 255*np.ones((HEIGHT, int(WIDTH*0.4),3), dtype=np.uint8)    \n",
    "    return {'image':image, \n",
    "            'keypoints':None,\n",
    "            'mask':image[:,:,0],\n",
    "            'text':'', \n",
    "            'male':0, \n",
    "            'female':0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "id": "e0c11bcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nplt.figure(figsize=(10,10))\\nret = get_sample(65718)\\nnew_img = ret['image'][:,:,::-1]\\nh, w, _ = new_img.shape\\nkp2img = Keypoints2Image('openpose_body_25', (h,w))\\nnew_kp_img = kp2img(np.expand_dims(ret['keypoints'],0))\\n\\n#new_kp_img = new_kp_img[:h,:w,:]\\nmerged = (new_kp_img*0.3 + 0.7*new_img)/255.\\nplt.imshow(merged)\\nplt.show()\\nplt.imshow(ret['mask'])\\nplt.show()\\n\\nplt.figure(figsize=(10,10))\\nret = augment(ret['image'], ret['keypoints'], mask=ret['mask'], scale=0.6)\\nnew_img = ret['image'][:,:,::-1]\\nh, w, _ = new_img.shape\\nkp2img = Keypoints2Image('openpose_body_25', (h,w))\\nnew_kp_img = kp2img(np.expand_dims(ret['keypoints'],0))\\nmerged = (new_kp_img*0.3 + 0.7*new_img)/255.\\nplt.imshow(merged)\\nplt.show()\\nplt.imshow(ret['mask'])\\n\""
      ]
     },
     "execution_count": 710,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_sample(sampled_idx,  angle=0., scale=1, crop_margin=0, mask_background=True):\n",
    "    row = df.iloc[sampled_idx]\n",
    "    keypoints = row.keypoints[0]\n",
    "    image = cv2.imread(dst_dir+row.image)\n",
    "    mask_file = (mask_dir+row.image).replace('.jpg','.bmp')\n",
    "    mask = cv2.imread(mask_file, 0)\n",
    "\n",
    "    ret = augment(image, keypoints, mask=mask, angle=angle, scale=scale, \n",
    "                   crop_margin=crop_margin, mask_background=mask_background)\n",
    "    \n",
    "    ret['text'] = row.text[0]\n",
    "    ret['male'] = row.male\n",
    "    ret['female'] = row.female\n",
    "    ret['pose_score'] = row.pose_score\n",
    "    return ret\n",
    "\n",
    "def augment(image, keypoints, mask=None, scale=1, angle=0, crop_margin=0, mask_background=False):\n",
    "\n",
    "    if mask_background and mask is not None:\n",
    "        image = cv2.bitwise_and(image, image, mask=mask)        \n",
    "        image[mask==0] = (255, 255, 255)\n",
    "    \n",
    "    height, width = image.shape[:2]\n",
    "    center = (width//2, height//2)\n",
    "    rotate_matrix = cv2.getRotationMatrix2D(center=center, angle=angle, scale=scale)\n",
    "    ty = int((1-scale)*height/2) if scale<=1 else 0\n",
    "    tx = 0\n",
    "    translation_matrix = np.array([[0, 0, tx],[0, 0, ty]])\n",
    "    rotate_matrix += translation_matrix\n",
    "    rotated_image = cv2.warpAffine(src=image, M=rotate_matrix, dsize=(width, height))\n",
    "    \n",
    "    if mask is not None:\n",
    "        rotated_mask = cv2.warpAffine(src=mask, M=rotate_matrix, dsize=(width, height))\n",
    "    else:\n",
    "        rotated_mask = None\n",
    "\n",
    "    # rotate keypoint\n",
    "    kp_ = deepcopy(keypoints)\n",
    "    kp_[:,2] = 1.\n",
    "    center = (0.5, 0.5)\n",
    "    rotate_matrix = cv2.getRotationMatrix2D(center=center, angle=angle, scale=scale)\n",
    "    ty = (1-scale)/2 if scale<=1 else 0\n",
    "    tx = 0\n",
    "    translation_matrix = np.array([[0, 0, tx],[0, 0, ty]])\n",
    "    rotate_matrix += translation_matrix\n",
    "\n",
    "    new_kp = np.dot(kp_, rotate_matrix.transpose())\n",
    "    new_kp = np.concatenate((new_kp, np.expand_dims(keypoints[:,2].transpose(), 1)), axis=1)\n",
    "    new_kp = new_kp.astype(np.float32)\n",
    "    \n",
    "    # crop\n",
    "    left = 0\n",
    "    right = width\n",
    "    if mask is not None:\n",
    "        vertical = np.mean(rotated_mask, axis=0)\n",
    "        for w in range(width):\n",
    "            if vertical[w] > 0.1:\n",
    "                left = w\n",
    "                break\n",
    "\n",
    "        for w in range(width-1, -1, -1):\n",
    "            if vertical[w] > 0.1:\n",
    "                right = w\n",
    "                break\n",
    "            \n",
    "        left = max(0, left-crop_margin)\n",
    "        right = min(width, right+crop_margin)\n",
    "        new_width = right - left\n",
    "        ratio = width/new_width\n",
    "        new_kp[:,0] = new_kp[:,0] - left/(width-1)\n",
    "    \n",
    "    new_kp[:,0] *= ratio\n",
    "    return {'image':rotated_image[:,left:right], \n",
    "            'keypoints':new_kp,\n",
    "            'mask':rotated_mask[:,left:right]}\n",
    "'''\n",
    "plt.figure(figsize=(10,10))\n",
    "ret = get_sample(65718)\n",
    "new_img = ret['image'][:,:,::-1]\n",
    "h, w, _ = new_img.shape\n",
    "kp2img = Keypoints2Image('openpose_body_25', (h,w))\n",
    "new_kp_img = kp2img(np.expand_dims(ret['keypoints'],0))\n",
    "\n",
    "#new_kp_img = new_kp_img[:h,:w,:]\n",
    "merged = (new_kp_img*0.3 + 0.7*new_img)/255.\n",
    "plt.imshow(merged)\n",
    "plt.show()\n",
    "plt.imshow(ret['mask'])\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "ret = augment(ret['image'], ret['keypoints'], mask=ret['mask'], scale=0.6)\n",
    "new_img = ret['image'][:,:,::-1]\n",
    "h, w, _ = new_img.shape\n",
    "kp2img = Keypoints2Image('openpose_body_25', (h,w))\n",
    "new_kp_img = kp2img(np.expand_dims(ret['keypoints'],0))\n",
    "merged = (new_kp_img*0.3 + 0.7*new_img)/255.\n",
    "plt.imshow(merged)\n",
    "plt.show()\n",
    "plt.imshow(ret['mask'])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "id": "35dc5457",
   "metadata": {},
   "outputs": [],
   "source": [
    "slots = []\n",
    "'''\n",
    "slots.append(get_sample(0))\n",
    "slots.append(get_empty_sample())\n",
    "slots.append(get_sample(2))\n",
    "slots.append(get_sample(5))\n",
    "slots.append(get_sample(4))\n",
    "'''\n",
    "slots.append(get_sample(65088, crop_margin=10))\n",
    "slots.append(get_sample(39848, crop_margin=10))\n",
    "slots.append(get_sample(21618, crop_margin=10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "id": "f5001060",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"    \\nret = combine_slots(slots, crop_margin=5)    \\nplt.figure(figsize=(10,10))\\nkp2img = Keypoints2Image('openpose_body_25')\\nkp_img = kp2img(ret['keypoints'])\\nimage = ret['image']\\nplt.imshow((kp_img*0.3+0.7*image[:,:,::-1])/255.)\\nplt.show()\\nplt.figure(figsize=(10,10))\\nplt.imshow(ret['mask'])\\n\""
      ]
     },
     "execution_count": 711,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def combine_slots(slots, crop_margin=0, space=0):\n",
    "    male_count = 0\n",
    "    female_count = 0\n",
    "    text = ''\n",
    "    merged = 255*np.ones((HEIGHT, WIDTH, 3), dtype=np.uint8)\n",
    "    merged_mask = np.zeros((HEIGHT, WIDTH), dtype=np.uint8)\n",
    "    \n",
    "    n_slots = len(slots)\n",
    "    slot_lens = [slot['image'].shape[1] for slot in slots]\n",
    "    total_width = sum(slot_lens)\n",
    "    total_width = max(WIDTH, total_width)\n",
    "    scale_factor = WIDTH/total_width \n",
    "    concat_kps = []\n",
    "    #space = 10 #pixels between people\n",
    "    pose_scores = []\n",
    "    start_x = 0\n",
    "    for i, slot in enumerate(slots):\n",
    "        slot_image = slot['image']\n",
    "        kp = slot['keypoints']            \n",
    "        mask = slot['mask']\n",
    "        h, w, _ = slot_image.shape\n",
    "\n",
    "        \n",
    "        if kp is not None: # if not empty slot\n",
    "            pose_scores.append(slot['pose_score'])\n",
    "            ret = augment(slot_image, kp, mask=mask, scale=scale_factor, crop_margin=crop_margin)    \n",
    "            slot_image = ret['image']\n",
    "            mask = ret['mask']\n",
    "            h, w, _ = slot_image.shape\n",
    "            cropped_height = max(0, int(math.ceil((1-scale_factor)*(h-1)))+2)\n",
    "            end_x = min(start_x + w, WIDTH-1)\n",
    "            capped_w = end_x - start_x\n",
    "            merged[cropped_height:, start_x:end_x] = slot_image[cropped_height:,:capped_w]\n",
    "            merged_mask[cropped_height:, start_x:end_x] = mask[cropped_height:,:capped_w]\n",
    "\n",
    "            kp = ret['keypoints']        \n",
    "            ratio = w/WIDTH\n",
    "            kp[:,0]= kp[:,0]*ratio +(start_x)/(WIDTH-1)\n",
    "            concat_kps.append(deepcopy(kp))\n",
    "            \n",
    "            male_count+= slot['male']\n",
    "            female_count+= slot['female']\n",
    "            text += slot['text']\n",
    "            #print(\"male\", male_count, 'female',female_count)\n",
    "        else:\n",
    "            end_x = start_x + int(0.8*scale_factor*w)\n",
    "        start_x = end_x + space\n",
    "    concat_kps = np.array(concat_kps)\n",
    "\n",
    "    return {'image':merged, \n",
    "            'keypoints':concat_kps,\n",
    "            'mask':merged_mask,\n",
    "            'text':text, \n",
    "            'male':male_count, \n",
    "            'female':female_count,\n",
    "            'pose_score':pose_scores}\n",
    "'''    \n",
    "ret = combine_slots(slots, crop_margin=5)    \n",
    "plt.figure(figsize=(10,10))\n",
    "kp2img = Keypoints2Image('openpose_body_25')\n",
    "kp_img = kp2img(ret['keypoints'])\n",
    "image = ret['image']\n",
    "plt.imshow((kp_img*0.3+0.7*image[:,:,::-1])/255.)\n",
    "plt.show()\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(ret['mask'])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "id": "f226f89c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 50000/50000 [26:30<00:00, 31.44it/s]\n",
      "100%|█████████████████████████████████████| 50000/50000 [41:08<00:00, 20.25it/s]\n"
     ]
    }
   ],
   "source": [
    "HEIGHT = 256\n",
    "WIDTH = 256\n",
    "multi_df = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "empty_percent = 0.0\n",
    "male_percent = 0.2\n",
    "random.seed(888)\n",
    "np.random.seed(888)\n",
    "N = len(df)\n",
    "male_indices = list(df[df.male>0].index)\n",
    "\n",
    "num_samples = {2:50000, 3:50000} # samples per numbeer of people\n",
    "\n",
    "for p, num_sample in num_samples.items():\n",
    "    for idx in tqdm(range(num_sample)):\n",
    "        num_slots = p\n",
    "        empty = random.uniform(0,1) < empty_percent\n",
    "        if empty: # have empty slot\n",
    "            num_slots += 1\n",
    "\n",
    "        slots_avail = [1 for _ in range(num_slots)]\n",
    "        if empty:\n",
    "            slots_avail[random.randrange(0,num_slots,1)] = 0\n",
    "        '''\n",
    "        print(\"num_slot\", num_slots)\n",
    "        print(\"empty_slot_id\", empty_slot_id)\n",
    "        print(\"slots_avail\", slots_avail)\n",
    "        '''\n",
    "        merged = np.zeros((TARGET_DIM, TARGET_DIM, 3), dtype=np.uint8)\n",
    "        slot_width = TARGET_DIM//num_slots\n",
    "\n",
    "        slots = []\n",
    "        slot_ids = []\n",
    "        captions = \"\"\n",
    "        male_count = 0\n",
    "        female_count = 0\n",
    "        crop_margin = 5\n",
    "        for not_empty in slots_avail:\n",
    "            if not not_empty:\n",
    "                slots.append(get_empty_sample())\n",
    "                continue\n",
    "            fail = True\n",
    "            while fail:\n",
    "                # for certain percentage, sample from male only\n",
    "                if random.uniform(0,1) < male_percent:\n",
    "                    sampled_idx = random.sample(male_indices, 1)[0]\n",
    "                    #print(\"sample male\", sampled_idx)\n",
    "                else:\n",
    "                    sampled_idx = random.randrange(N)\n",
    "                sample = get_sample(sampled_idx, crop_margin=crop_margin+5)\n",
    "                # only use picture that is show entire head\n",
    "                if np.sum(sample['mask'], axis=1)[0]==0:\n",
    "                    fail = False\n",
    "                else:\n",
    "                    fail = True\n",
    "                    \n",
    "            #print(sampled_idx)\n",
    "            slot_ids.append(str(sampled_idx))\n",
    "            slots.append(sample)\n",
    "\n",
    "        ret = combine_slots(slots, crop_margin, space=0)\n",
    "        merged = ret['image']\n",
    "        mask = ret['mask']\n",
    "        '''\n",
    "        plt.imshow(merged[:,:,::-1])\n",
    "        plt.show()\n",
    "        \n",
    "        plt.imshow(ret['mask'])\n",
    "        plt.show()\n",
    "        '''\n",
    "        fname = '_'.join(slot_ids)\n",
    "        dst_file = os.path.join(multi_dst_dir, f'{fname}.png')        \n",
    "        cv2.imwrite(dst_file, merged)\n",
    "        mask_file = os.path.join(multi_mask_dir, f'{fname}.bmp')\n",
    "        cv2.imwrite(mask_file, mask)\n",
    "        new_row = {'image':dst_file.replace('../data/',''), \n",
    "                   'text':[ret['text']],\n",
    "                   'keypoints':ret['keypoints'], \n",
    "                   'num_people':p, \n",
    "                   'female':ret['female'], \n",
    "                   'male':ret['male'],\n",
    "                   'pose_score':ret['pose_score']}\n",
    "        multi_df = multi_df.append(new_row, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "id": "56eb1844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>text</th>\n",
       "      <th>num_people</th>\n",
       "      <th>keypoints</th>\n",
       "      <th>pose_score</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_multi_256/65088_39848.png</td>\n",
       "      <td>[the lady wore a white sleeveless dress.the la...</td>\n",
       "      <td>2</td>\n",
       "      <td>[[[0.16590784, 0.11919098, 0.90167606], [0.171...</td>\n",
       "      <td>[[0.65654844], [0.53469163]]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img_multi_256/21618_60094.png</td>\n",
       "      <td>[the lady was wearing a red sleeveless tank.th...</td>\n",
       "      <td>2</td>\n",
       "      <td>[[[0.122911714, 0.36436075, 0.90818834], [0.10...</td>\n",
       "      <td>[[0.8420277], [0.7847611]]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_multi_256/41274_6689.png</td>\n",
       "      <td>[the lady is wearing a gray long-sleeved jacke...</td>\n",
       "      <td>2</td>\n",
       "      <td>[[[0.24023373, 0.20909551, 0.89905256], [0.256...</td>\n",
       "      <td>[[0.45582512], [0.7980377]]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img_multi_256/40138_44021.png</td>\n",
       "      <td>[the lady was wearing a white long-sleeved swe...</td>\n",
       "      <td>2</td>\n",
       "      <td>[[[0.2378331, 0.20879744, 0.9183851], [0.22754...</td>\n",
       "      <td>[[0.5174534], [0.48361027]]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img_multi_256/70297_17664.png</td>\n",
       "      <td>[the lady wore a black long-sleeved dress.the ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[[[0.21651572, 0.19086367, 0.8681383], [0.2758...</td>\n",
       "      <td>[[0.40513298], [0.4845749]]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>img_multi_256/27596_35660_38342.png</td>\n",
       "      <td>[the lady wore a black sleeveless top.the lady...</td>\n",
       "      <td>3</td>\n",
       "      <td>[[[0.16470154, 0.44366732, 0.86534953], [0.159...</td>\n",
       "      <td>[[0.49246684], [0.44571579], [0.33535275]]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>img_multi_256/37284_71119_3035.png</td>\n",
       "      <td>[the man wore gray long-sleeved cardigan.the l...</td>\n",
       "      <td>3</td>\n",
       "      <td>[[[0.09391874, 0.5262225, 0.88526535], [0.1743...</td>\n",
       "      <td>[[0.38793764], [0.42934003], [0.4358484]]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>img_multi_256/2833_58087_17586.png</td>\n",
       "      <td>[the lady was wearing a white long-sleeved blo...</td>\n",
       "      <td>3</td>\n",
       "      <td>[[[0.16071099, 0.35884577, 0.899058], [0.12201...</td>\n",
       "      <td>[[0.7516109], [0.5253461], [0.4569836]]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>img_multi_256/27519_19941_21977.png</td>\n",
       "      <td>[the lady is wearing a white long-sleeved tee....</td>\n",
       "      <td>3</td>\n",
       "      <td>[[[0.124214366, 0.41919452, 0.8980003], [0.133...</td>\n",
       "      <td>[[0.76353186], [0.4450743], [0.4255491]]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>img_multi_256/7647_44312_72263.png</td>\n",
       "      <td>[the lady is wearing a red long-sleeved blazer...</td>\n",
       "      <td>3</td>\n",
       "      <td>[[[0.16787241, 0.409813, 0.87604535], [0.17754...</td>\n",
       "      <td>[[0.46983215], [0.44079453, 0.12429804], [0.73...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     image  \\\n",
       "0            img_multi_256/65088_39848.png   \n",
       "1            img_multi_256/21618_60094.png   \n",
       "2             img_multi_256/41274_6689.png   \n",
       "3            img_multi_256/40138_44021.png   \n",
       "4            img_multi_256/70297_17664.png   \n",
       "...                                    ...   \n",
       "99995  img_multi_256/27596_35660_38342.png   \n",
       "99996   img_multi_256/37284_71119_3035.png   \n",
       "99997   img_multi_256/2833_58087_17586.png   \n",
       "99998  img_multi_256/27519_19941_21977.png   \n",
       "99999   img_multi_256/7647_44312_72263.png   \n",
       "\n",
       "                                                    text num_people  \\\n",
       "0      [the lady wore a white sleeveless dress.the la...          2   \n",
       "1      [the lady was wearing a red sleeveless tank.th...          2   \n",
       "2      [the lady is wearing a gray long-sleeved jacke...          2   \n",
       "3      [the lady was wearing a white long-sleeved swe...          2   \n",
       "4      [the lady wore a black long-sleeved dress.the ...          2   \n",
       "...                                                  ...        ...   \n",
       "99995  [the lady wore a black sleeveless top.the lady...          3   \n",
       "99996  [the man wore gray long-sleeved cardigan.the l...          3   \n",
       "99997  [the lady was wearing a white long-sleeved blo...          3   \n",
       "99998  [the lady is wearing a white long-sleeved tee....          3   \n",
       "99999  [the lady is wearing a red long-sleeved blazer...          3   \n",
       "\n",
       "                                               keypoints  \\\n",
       "0      [[[0.16590784, 0.11919098, 0.90167606], [0.171...   \n",
       "1      [[[0.122911714, 0.36436075, 0.90818834], [0.10...   \n",
       "2      [[[0.24023373, 0.20909551, 0.89905256], [0.256...   \n",
       "3      [[[0.2378331, 0.20879744, 0.9183851], [0.22754...   \n",
       "4      [[[0.21651572, 0.19086367, 0.8681383], [0.2758...   \n",
       "...                                                  ...   \n",
       "99995  [[[0.16470154, 0.44366732, 0.86534953], [0.159...   \n",
       "99996  [[[0.09391874, 0.5262225, 0.88526535], [0.1743...   \n",
       "99997  [[[0.16071099, 0.35884577, 0.899058], [0.12201...   \n",
       "99998  [[[0.124214366, 0.41919452, 0.8980003], [0.133...   \n",
       "99999  [[[0.16787241, 0.409813, 0.87604535], [0.17754...   \n",
       "\n",
       "                                              pose_score  female  male  \n",
       "0                           [[0.65654844], [0.53469163]]     2.0   0.0  \n",
       "1                             [[0.8420277], [0.7847611]]     2.0   0.0  \n",
       "2                            [[0.45582512], [0.7980377]]     1.0   1.0  \n",
       "3                            [[0.5174534], [0.48361027]]     2.0   0.0  \n",
       "4                            [[0.40513298], [0.4845749]]     2.0   0.0  \n",
       "...                                                  ...     ...   ...  \n",
       "99995         [[0.49246684], [0.44571579], [0.33535275]]     3.0   0.0  \n",
       "99996          [[0.38793764], [0.42934003], [0.4358484]]     2.0   1.0  \n",
       "99997            [[0.7516109], [0.5253461], [0.4569836]]     3.0   0.0  \n",
       "99998           [[0.76353186], [0.4450743], [0.4255491]]     2.0   1.0  \n",
       "99999  [[0.46983215], [0.44079453, 0.12429804], [0.73...     3.0   0.0  \n",
       "\n",
       "[100000 rows x 7 columns]"
      ]
     },
     "execution_count": 716,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "id": "adcf249c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.image = df.image.map(lambda x: 'img_256/'+x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "id": "53859c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_123 = pd.concat([df, multi_df], ignore_index=True)\n",
    "df_123.to_pickle(\"../data/deepfashion_123.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "id": "96e2df39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(df_123, test_size=1000, random_state=388)\n",
    "test_df.reset_index(inplace=True)\n",
    "train_df.reset_index(inplace=True)\n",
    "train_df.to_pickle('../data/deepfashion_123_train.pickle')\n",
    "test_df.to_pickle('../data/deepfashion_123_test.pickle')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vqgan_clip",
   "language": "python",
   "name": "vqgan_clip"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
